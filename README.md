# ðŸ¤– Gemini RAG Chatbot Assistant

**Gemini RAG Chatbot Assistant** is a web-based chatbot that uses Retrieval-Augmented Generation (RAG) in combination with Googleâ€™s Gemini AI model to answer user queries more accurately by referencing relevant documents. The interface is clean, intuitive, and supports basic Markdown formatting such as lists and bold text.

---

## Features

- Chat interface for user interaction with the AI via browser
- Integration with Gemini API using your own API key
- RAG-powered: fetches document snippets to enhance response quality
- Supports formatting:
  - `**bold text**` â†’ `<b>`
  - `* unordered list` â†’ `<ul><li>...</li></ul>`
  - `1. ordered list` â†’ `<ol><li>...</li></ol>`
- HTML sanitization using `bleach` to prevent XSS
- Easy deployment with Docker

---

## How to Get a Gemini API Key

To use the Gemini model, you'll need a valid API key from Google. Follow these steps:

1. Go to: [https://makersuite.google.com/app/apikey](https://makersuite.google.com/app/apikey)
2. Log in with your Google account.
3. Click **"Create API key"**.
4. Copy and save the key for the next step.

---

## Running with Docker

You donâ€™t need to install any dependencies â€” just Docker. Run this command:

```bash
docker run -d \
  --name chatbot \
  -p <your_port>:<your_port> \
  -e PORT=<your_port> \
  -e GOOGLE_API_KEY=<your_gemini_api_key> \
  -e APP_SESSION_SECRET_KEY=<your_session_secret_key> \
  qctrung/rag-chatbot-assistant-app:latest
````

Replace:

- `<your_gemini_api_key>` with the API key you got from Google.
- `<your_session_secret_key>` with a custom string to secure Flask session (e.g., `"supersecret123"`).

Once running, open your browser and go to: `http://localhost:<your_port>`

---

## User Interface

Built using pure HTML and CSS â€” no build step needed. Highlights:

- Clean and responsive chat UI
- Auto-scrolls to the latest message
- Bold text and list rendering supported
- Scrollable chat container (instead of scrolling the entire page)
- Chat history stored in Flask session memory

### Demo

![User interface](./assets/user_interface.png)

![Bot is answering](./assets/bot_answering.png)

![First answer](./assets/first_answer.png)

![Bot is answering the second question](./assets/bot_answer_second_question.png)

![Second answer](./assets/second_answer.png)

---

## Project Structure

```bash
â”œâ”€â”€ ./app.py
â”œâ”€â”€ ./corpus
â”‚Â Â  â”œâ”€â”€ ./corpus/techshop-faq.pdf
â”‚Â Â  â”œâ”€â”€ ./corpus/techshop-troubleshooting-guide.pdf
â”‚Â Â  â””â”€â”€ ./corpus/techshop-user-guide.pdf
â”œâ”€â”€ ./Dockerfile
â”œâ”€â”€ ./README.md
â”œâ”€â”€ ./requirements.txt
â”œâ”€â”€ ./src
â”‚Â Â  â”œâ”€â”€ ./src/gemini_rag_model.py
â”‚Â Â  â”œâ”€â”€ ./src/__init__.py
â”‚Â Â  â””â”€â”€ ./src/utils.py
â”œâ”€â”€ ./static
â”‚Â Â  â”œâ”€â”€ ./static/script.js
â”‚Â Â  â””â”€â”€ ./static/style.css
â””â”€â”€ ./templates
    â””â”€â”€ ./templates/index.html
```

---

## How It Works (Technical Details)

The chatbot uses **RAG (Retrieval-Augmented Generation)** to ground its responses in your own documents. Here's how it works under the hood:

### Document Loading

When the application starts:

1. It scans the `corpus/` directory for PDF files.
2. It reads and uploads these files to **Gemini's cached cloud storage** using the `google.genai` Python client.
3. These uploaded documents form a **persistent context** available during chatbot interactions.

### Inference Flow

Every time the user sends a message:

1. The `prompt` is combined with the previously uploaded documents (`self.corpus`) as input to the Gemini model.
2. The model (`gemini-2.0-flash`, by default) is queried with:

    ```python
    contents=[*self.corpus, formatted_prompt],
    config={
        "system_instruction": system_instruction,
        "temperature": 0.2,
        "top_p": 0.8,
        "top_k": 20
    }
    ```

3. Gemini generates a response grounded in the uploaded documents.
4. The raw response is then passed through formatting & sanitization steps before being displayed to the user.

> This allows your chatbot to provide **accurate and relevant answers** based on your actual website documents (e.g., guides, help center, terms, etc.).

---

## Corpus Folder Structure

Make sure your PDFs are placed inside a `corpus/` directory at the root of the project:

```bash
corpus/
â”œâ”€â”€ techshop-faq.pdf
â”œâ”€â”€ techshop-troubleshooting-guide.pdf
â””â”€â”€ techshop-user-guide.pdf
```

You can customize this list as needed. The model supports any number of files as long as it fits Geminiâ€™s API input constraints.

---

## Security Notes

= Never commit your `.env` or real API keys to a public repository.
= API keys and secret keys should be passed via environment variables (as shown in the Docker command).
= All chatbot responses are sanitized with `bleach` to prevent script injection (XSS).

---

## Thanks for using this project

Developed by [@lngquoctrung](https://github.com/lngquoctrung).
Feel free to open an issue, contribute, or ask questions!

---

Let me know if you'd like to:

- Add badges (e.g., Docker Pulls, Build Passing)
- Include automated deployment instructions
- Generate a `.env.example` or Docker Compose setup

I'm happy to assist with polishing or expanding the docs further!
